{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8df0ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report ,accuracy_score ,confusion_matrix\n",
    "import re\n",
    "import joblib\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cc89a1",
   "metadata": {},
   "source": [
    "dataset ko read karna karna with the helo of panda built-in function ! read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f22ff5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('fake_news_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77cacf8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Foreign Democrat final.</td>\n",
       "      <td>more tax development both store agreement lawy...</td>\n",
       "      <td>10/03/2023</td>\n",
       "      <td>NY Times</td>\n",
       "      <td>Paula George</td>\n",
       "      <td>Politics</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To offer down resource great point.</td>\n",
       "      <td>probably guess western behind likely next inve...</td>\n",
       "      <td>25/05/2022</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>Joseph Hill</td>\n",
       "      <td>Politics</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Himself church myself carry.</td>\n",
       "      <td>them identify forward present success risk sev...</td>\n",
       "      <td>01/09/2022</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Julia Robinson</td>\n",
       "      <td>Business</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You unit its should.</td>\n",
       "      <td>phone which item yard Republican safe where po...</td>\n",
       "      <td>07/02/2023</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Mr. David Foster DDS</td>\n",
       "      <td>Science</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Billion believe employee summer how.</td>\n",
       "      <td>wonder myself fact difficult course forget exa...</td>\n",
       "      <td>03/04/2023</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Austin Walker</td>\n",
       "      <td>Technology</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  \\\n",
       "0               Foreign Democrat final.   \n",
       "1   To offer down resource great point.   \n",
       "2          Himself church myself carry.   \n",
       "3                  You unit its should.   \n",
       "4  Billion believe employee summer how.   \n",
       "\n",
       "                                                text        date    source  \\\n",
       "0  more tax development both store agreement lawy...  10/03/2023  NY Times   \n",
       "1  probably guess western behind likely next inve...  25/05/2022  Fox News   \n",
       "2  them identify forward present success risk sev...  01/09/2022       CNN   \n",
       "3  phone which item yard Republican safe where po...  07/02/2023   Reuters   \n",
       "4  wonder myself fact difficult course forget exa...  03/04/2023       CNN   \n",
       "\n",
       "                 author    category label  \n",
       "0          Paula George    Politics  real  \n",
       "1           Joseph Hill    Politics  fake  \n",
       "2        Julia Robinson    Business  fake  \n",
       "3  Mr. David Foster DDS     Science  fake  \n",
       "4         Austin Walker  Technology  fake  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beca617d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns Index(['title', 'text', 'date', 'source', 'author', 'category', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('columns' , dataset.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7255c4",
   "metadata": {},
   "source": [
    "NEcha ham dataset ka un field ko use karain ga jin ka hamain zaroorat ho ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bf2352d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Dateset with required fields\n",
      "                                                    text label\n",
      "0      more tax development both store agreement lawy...  real\n",
      "1      probably guess western behind likely next inve...  fake\n",
      "2      them identify forward present success risk sev...  fake\n",
      "3      phone which item yard Republican safe where po...  fake\n",
      "4      wonder myself fact difficult course forget exa...  fake\n",
      "...                                                  ...   ...\n",
      "19995  hit and television I change very our happy doo...  fake\n",
      "19996  fear most meet rock even sea value design stan...  real\n",
      "19997  activity loss very provide eye west create wha...  real\n",
      "19998  term point general common training watch respo...  fake\n",
      "19999  remain pressure glass me six senior though nor...  fake\n",
      "\n",
      "[20000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset[[\"text\" , \"label\"]]\n",
    "print(\"New Dateset with required fields\")\n",
    "print(dataset);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba4a5ef",
   "metadata": {},
   "source": [
    "we gonna clear all the null values in out dateset now. Ml model khali dataset sa kuch nai seek sakta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9ede65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1779157a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after cleaning (20000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>more tax development both store agreement lawy...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>probably guess western behind likely next inve...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>them identify forward present success risk sev...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phone which item yard Republican safe where po...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wonder myself fact difficult course forget exa...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  more tax development both store agreement lawy...  real\n",
       "1  probably guess western behind likely next inve...  fake\n",
       "2  them identify forward present success risk sev...  fake\n",
       "3  phone which item yard Republican safe where po...  fake\n",
       "4  wonder myself fact difficult course forget exa...  fake"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"shape after cleaning\" , dataset.shape\n",
    ")\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90a256d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Mr-\n",
      "[nltk_data]     Imperfect\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Text cleaned successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)      # Remove digits\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "dataset['text'] = dataset['text'].apply(clean_text)\n",
    "print(\"✅ Text cleaned successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f61229ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Mr-\n",
      "[nltk_data]     Imperfect\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()                          # lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)          # remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)              # remove digits\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])  # remove stopwords\n",
    "    return text\n",
    "\n",
    "# Apply it\n",
    "dataset['text'] = dataset['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b3850",
   "metadata": {},
   "source": [
    "Text vectorization : Ham is ma convert kar dain ga text data to numbers ma ta k model samaj saka data ko\n",
    "\n",
    "What is TF-IDF?\n",
    "\n",
    "TF-IDF stands for:\n",
    "\n",
    "    Term Frequency – how often a word appears in a document\n",
    "\n",
    "    Inverse Document Frequency – how rare a word is across all documents\n",
    "\n",
    "    It tells the model:\n",
    "    “This word appears a lot in this article but not in most others — so it’s important!”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0d21d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Accuracy: 50.80%\n",
      "📋 Confusion Matrix:\n",
      "[[1207  822]\n",
      " [1146  825]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset['text'], dataset['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "\n",
    "# Fit and transform training data, only transform test\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train model\n",
    "\n",
    "# Model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "print(f\"📊 Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "print(\"📋 Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd64a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
